{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEzaLBfJhEBrhsWPltVEP3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBesat-SoftW/AstroBesat-SoftW/blob/main/3_version_coklu_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOSYA ADI: egitim_stacking.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import joblib # Sklearn/XGBoost modellerini kaydetmek iÃ§in\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "\n",
        "# --- 1. ADIM: VERÄ° ÃœRETÄ°MÄ° (AynÄ± kalÄ±yor) ---\n",
        "print(\">> Veri Ã¼retiliyor (50.000 Adet)...\") # HÄ±z iÃ§in sayÄ±yÄ± 50k yaptÄ±m, artÄ±rabilirsin.\n",
        "\n",
        "def veri_uret(n):\n",
        "    dna_seqs, prot_seqs, bio_feats, labels = [], [], [], []\n",
        "    amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "\n",
        "    for _ in range(n):\n",
        "        dna = ''.join(np.random.choice(list('ACGT'), size=11))\n",
        "        prot = ''.join(np.random.choice(amino_acids, size=11))\n",
        "\n",
        "        # SayÄ±sal Ã¶zellikler\n",
        "        risk = np.random.beta(2, 2)\n",
        "        maf = np.random.exponential(0.05)\n",
        "        cons = np.random.uniform(0, 10)\n",
        "        hydro = np.random.uniform(-5, 5)\n",
        "        polar = np.random.uniform(-3, 3)\n",
        "        weight = np.random.uniform(-50, 50)\n",
        "\n",
        "        # Etiketleme (Biraz gÃ¼rÃ¼ltÃ¼ eklenmiÅŸ)\n",
        "        score = (risk * 0.4) + (cons/10 * 0.2) + ((0.5 - maf)*2 * 0.2) + (abs(hydro)/5 * 0.2)\n",
        "        score += np.random.normal(0, 0.05)\n",
        "        label = 1 if score > 0.65 else 0\n",
        "\n",
        "        dna_seqs.append(dna)\n",
        "        prot_seqs.append(prot)\n",
        "        bio_feats.append([risk, maf, cons, hydro, polar, weight])\n",
        "        labels.append(label)\n",
        "\n",
        "    # DataFrame'e Ã§evirelim (Tabular modeller iÃ§in kolaylÄ±k olsun)\n",
        "    df_feat = pd.DataFrame(bio_feats, columns=['Risk', 'MAF', 'Cons', 'Hydro', 'Polar', 'Weight'])\n",
        "    return dna_seqs, prot_seqs, df_feat, np.array(labels)\n",
        "\n",
        "dna_data, prot_data, X_num, y = veri_uret(50000)\n",
        "\n",
        "# --- 2. ADIM: Ã–N Ä°ÅLEME ---\n",
        "# Tokenizer\n",
        "dna_tok = Tokenizer(char_level=True)\n",
        "dna_tok.fit_on_texts(dna_data)\n",
        "X_dna = pad_sequences(dna_tok.texts_to_sequences(dna_data), maxlen=11, padding='post')\n",
        "\n",
        "prot_tok = Tokenizer(char_level=True)\n",
        "prot_tok.fit_on_texts(prot_data)\n",
        "X_prot = pad_sequences(prot_tok.texts_to_sequences(prot_data), maxlen=11, padding='post')\n",
        "\n",
        "# --- 3. ADIM: STACKING Ä°Ã‡Ä°N VERÄ° BÃ–LME ---\n",
        "# Stacking'de en Ã¶nemli kural: Meta-Model, Base modellerin eÄŸitimde gÃ¶rmediÄŸi veriyle eÄŸitilmelidir!\n",
        "# Bu yÃ¼zden veriyi 3 parÃ§aya bÃ¶lÃ¼yoruz:\n",
        "# 1. Base_Train (%60): Temel modelleri eÄŸitmek iÃ§in.\n",
        "# 2. Meta_Train (%20): Temel modellerin tahmin Ã¼retip Meta modelin eÄŸitilmesi iÃ§in.\n",
        "# 3. Test (%20): Nihai baÅŸarÄ±yÄ± Ã¶lÃ§mek iÃ§in.\n",
        "\n",
        "# Ã–nce Test'i ayÄ±ralÄ±m\n",
        "X_dna_temp, X_dna_test, X_prot_temp, X_prot_test, X_num_temp, X_num_test, y_temp, y_test = train_test_split(\n",
        "    X_dna, X_prot, X_num, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# KalanÄ± Base ve Meta olarak ayÄ±ralÄ±m\n",
        "X_dna_base, X_dna_meta, X_prot_base, X_prot_meta, X_num_base, X_num_meta, y_base, y_meta = train_test_split(\n",
        "    X_dna_temp, X_prot_temp, X_num_temp, y_temp, test_size=0.25, random_state=42 # 0.25 * 0.8 = 0.20 ToplamÄ±n %20'si\n",
        ")\n",
        "\n",
        "print(f\">> Veri BÃ¶lÃ¼ndÃ¼: Base EÄŸitim: {len(y_base)}, Meta EÄŸitim: {len(y_meta)}, Test: {len(y_test)}\")\n",
        "\n",
        "# --- 4. ADIM: BASE MODELLERÄ°N EÄÄ°TÄ°MÄ° ---\n",
        "\n",
        "# === MODEL 1: DERÄ°N Ã–ÄRENME (CNN) ===\n",
        "# Hem dizileri hem sayÄ±sal veriyi kullanÄ±r\n",
        "print(\"\\n>> 1/3 Derin Ã–ÄŸrenme Modeli (CNN) EÄŸitiliyor...\")\n",
        "in_dna = Input(shape=(11,))\n",
        "emb_dna = Embedding(len(dna_tok.word_index)+1, 8)(in_dna)\n",
        "x1 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_dna))\n",
        "\n",
        "in_prot = Input(shape=(11,))\n",
        "emb_prot = Embedding(len(prot_tok.word_index)+1, 8)(in_prot)\n",
        "x2 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_prot))\n",
        "\n",
        "in_num_layer = Input(shape=(6,))\n",
        "x3 = BatchNormalization()(Dense(16, activation='relu')(in_num_layer))\n",
        "\n",
        "merged = Concatenate()([x1, x2, x3])\n",
        "z = Dropout(0.3)(Dense(32, activation='relu')(merged))\n",
        "out = Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "model_cnn = Model(inputs=[in_dna, in_prot, in_num_layer], outputs=out)\n",
        "model_cnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "model_cnn.fit([X_dna_base, X_prot_base, X_num_base], y_base, epochs=5, batch_size=32, verbose=0)\n",
        "print(\"   âœ… CNN TamamlandÄ±.\")\n",
        "\n",
        "# === MODEL 2: XGBOOST ===\n",
        "# Sadece SayÄ±sal veriyi sever (Dizi verisi vermiyoruz, sadece X_num)\n",
        "print(\">> 2/3 XGBoost Modeli EÄŸitiliyor...\")\n",
        "model_xgb = xgb.XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=4, use_label_encoder=False, eval_metric='logloss')\n",
        "model_xgb.fit(X_num_base, y_base)\n",
        "print(\"   âœ… XGBoost TamamlandÄ±.\")\n",
        "\n",
        "# === MODEL 3: LIGHTGBM ===\n",
        "# Sadece SayÄ±sal veriyi sever\n",
        "print(\">> 3/3 LightGBM Modeli EÄŸitiliyor...\")\n",
        "model_lgbm = lgb.LGBMClassifier(n_estimators=100, learning_rate=0.1, verbose=-1)\n",
        "model_lgbm.fit(X_num_base, y_base)\n",
        "print(\"   âœ… LightGBM TamamlandÄ±.\")\n",
        "\n",
        "\n",
        "# --- 5. ADIM: META-LEARNER (STACKING) EÄÄ°TÄ°MÄ° ---\n",
        "print(\"\\n>> Meta-Learner iÃ§in Tahminler ToplanÄ±yor...\")\n",
        "\n",
        "# Meta seti Ã¼zerinde modellerin \"fikirlerini\" (olasÄ±lÄ±klarÄ±nÄ±) alÄ±yoruz\n",
        "pred_cnn_meta = model_cnn.predict([X_dna_meta, X_prot_meta, X_num_meta], verbose=0).flatten()\n",
        "pred_xgb_meta = model_xgb.predict_proba(X_num_meta)[:, 1] # 1 olma olasÄ±lÄ±ÄŸÄ±\n",
        "pred_lgbm_meta = model_lgbm.predict_proba(X_num_meta)[:, 1]\n",
        "\n",
        "# Bu tahminleri yeni bir DataFrame'de birleÅŸtiriyoruz\n",
        "# Bu tablo: [CNN_Fikri, XGB_Fikri, LGBM_Fikri] -> GerÃ§ek_Label\n",
        "X_stack_meta = np.column_stack((pred_cnn_meta, pred_xgb_meta, pred_lgbm_meta))\n",
        "\n",
        "print(\">> Meta-Learner (Logistic Regression) EÄŸitiliyor...\")\n",
        "meta_model = LogisticRegression()\n",
        "meta_model.fit(X_stack_meta, y_meta)\n",
        "\n",
        "# --- 6. ADIM: TEST PERFORMANSI ---\n",
        "print(\"\\n>> FÄ°NAL TESTÄ° (HiÃ§ GÃ¶rÃ¼lmemiÅŸ Veriyle)...\")\n",
        "\n",
        "# Test seti iÃ§in tahminleri al\n",
        "p1 = model_cnn.predict([X_dna_test, X_prot_test, X_num_test], verbose=0).flatten()\n",
        "p2 = model_xgb.predict_proba(X_num_test)[:, 1]\n",
        "p3 = model_lgbm.predict_proba(X_num_test)[:, 1]\n",
        "\n",
        "# BirleÅŸtir\n",
        "X_stack_test = np.column_stack((p1, p2, p3))\n",
        "\n",
        "# Meta model karar versin\n",
        "final_preds = meta_model.predict(X_stack_test)\n",
        "\n",
        "print(f\"STACKING F1 SKORU: {f1_score(y_test, final_preds):.4f}\")\n",
        "print(f\"STACKING ACCURACY: {accuracy_score(y_test, final_preds):.4f}\")\n",
        "print(\"Meta Model AÄŸÄ±rlÄ±klarÄ± (Hangi modele ne kadar gÃ¼vendi?):\")\n",
        "print(f\"CNN: {meta_model.coef_[0][0]:.2f}, XGB: {meta_model.coef_[0][1]:.2f}, LGBM: {meta_model.coef_[0][2]:.2f}\")\n",
        "\n",
        "# --- 7. ADIM: KAYIT ---\n",
        "print(\"\\n>> TÃ¼m modeller kaydediliyor...\")\n",
        "import os\n",
        "if not os.path.exists('model_stack'): os.makedirs('model_stack')\n",
        "\n",
        "# 1. Base Modeller\n",
        "model_cnn.save('model_stack/base_cnn.h5')\n",
        "joblib.dump(model_xgb, 'model_stack/base_xgb.pkl')\n",
        "joblib.dump(model_lgbm, 'model_stack/base_lgbm.pkl')\n",
        "\n",
        "# 2. Meta Model\n",
        "joblib.dump(meta_model, 'model_stack/meta_model.pkl')\n",
        "\n",
        "# 3. Tokenizerlar\n",
        "with open('model_stack/dna_tok.pickle', 'wb') as f: pickle.dump(dna_tok, f)\n",
        "with open('model_stack/prot_tok.pickle', 'wb') as f: pickle.dump(prot_tok, f)\n",
        "\n",
        "# 4. Test iÃ§in Ã¶rnek bir veri dosyasÄ± kaydedelim (doÄŸrulama kodunda kullanmak iÃ§in)\n",
        "# GerÃ§ek veriler ve sonuÃ§larÄ± birleÅŸtirip kaydediyoruz\n",
        "test_df = X_num_test.copy()\n",
        "test_df['DNA_Dizisi'] = dna_tok.sequences_to_texts(X_dna_test)\n",
        "test_df['DNA_Dizisi'] = test_df['DNA_Dizisi'].apply(lambda x: x.replace(' ', '').upper())\n",
        "test_df['Protein_Dizisi'] = prot_tok.sequences_to_texts(X_prot_test)\n",
        "test_df['Protein_Dizisi'] = test_df['Protein_Dizisi'].apply(lambda x: x.replace(' ', '').upper())\n",
        "test_df['Gercek_Deger'] = y_test\n",
        "\n",
        "test_df.to_csv('test_verileri_stacking.csv', index=False)\n",
        "print(\"âœ… Her ÅŸey kaydedildi! 'model_stack' klasÃ¶rÃ¼nÃ¼ kontrol edin.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTeJdlWYzOHe",
        "outputId": "38c4376c-b4ae-4305-96e2-5914f4533843"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Veri Ã¼retiliyor (50.000 Adet)...\n",
            ">> Veri BÃ¶lÃ¼ndÃ¼: Base EÄŸitim: 30000, Meta EÄŸitim: 10000, Test: 10000\n",
            "\n",
            ">> 1/3 Derin Ã–ÄŸrenme Modeli (CNN) EÄŸitiliyor...\n",
            "   âœ… CNN TamamlandÄ±.\n",
            ">> 2/3 XGBoost Modeli EÄŸitiliyor...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/xgboost/training.py:199: UserWarning: [00:51:20] WARNING: /workspace/src/learner.cc:790: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   âœ… XGBoost TamamlandÄ±.\n",
            ">> 3/3 LightGBM Modeli EÄŸitiliyor...\n",
            "   âœ… LightGBM TamamlandÄ±.\n",
            "\n",
            ">> Meta-Learner iÃ§in Tahminler ToplanÄ±yor...\n",
            ">> Meta-Learner (Logistic Regression) EÄŸitiliyor...\n",
            "\n",
            ">> FÄ°NAL TESTÄ° (HiÃ§ GÃ¶rÃ¼lmemiÅŸ Veriyle)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "STACKING F1 SKORU: 0.8273\n",
            "STACKING ACCURACY: 0.8954\n",
            "Meta Model AÄŸÄ±rlÄ±klarÄ± (Hangi modele ne kadar gÃ¼vendi?):\n",
            "CNN: 5.39, XGB: 2.23, LGBM: -0.54\n",
            "\n",
            ">> TÃ¼m modeller kaydediliyor...\n",
            "âœ… Her ÅŸey kaydedildi! 'model_stack' klasÃ¶rÃ¼nÃ¼ kontrol edin.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOSYA ADI: test_stacking.py\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import joblib\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "print(\">> Modeller ve SÃ¶zlÃ¼kler yÃ¼kleniyor...\")\n",
        "\n",
        "# 1. YÃœKLEME Ä°ÅLEMLERÄ°\n",
        "# SÃ¶zlÃ¼kler\n",
        "with open('model_stack/dna_tok.pickle', 'rb') as f: dna_tok = pickle.load(f)\n",
        "with open('model_stack/prot_tok.pickle', 'rb') as f: prot_tok = pickle.load(f)\n",
        "\n",
        "# Base Modeller\n",
        "model_cnn = load_model('model_stack/base_cnn.h5')\n",
        "model_xgb = joblib.load('model_stack/base_xgb.pkl')\n",
        "model_lgbm = joblib.load('model_stack/base_lgbm.pkl')\n",
        "\n",
        "# Meta Model\n",
        "meta_model = joblib.load('model_stack/meta_model.pkl')\n",
        "\n",
        "print(\"âœ… Sistem HazÄ±r.\")\n",
        "\n",
        "# 2. TEST VERÄ°SÄ°NDEN RASTGELE HASTA Ã‡EK\n",
        "try:\n",
        "    df = pd.read_csv('test_verileri_stacking.csv')\n",
        "    hasta = df.sample(1).iloc[0]\n",
        "except:\n",
        "    print(\"Test verisi bulunamadÄ±, lÃ¼tfen Ã¶nce eÄŸitimi Ã§alÄ±ÅŸtÄ±rÄ±n.\")\n",
        "    exit()\n",
        "\n",
        "# Gelen Ham Veriler\n",
        "raw_dna = hasta['DNA_Dizisi']\n",
        "raw_prot = hasta['Protein_Dizisi']\n",
        "raw_feats = hasta[['Risk', 'MAF', 'Cons', 'Hydro', 'Polar', 'Weight']].values.reshape(1, -1) # (1, 6) formatÄ±nda\n",
        "gercek_durum = int(hasta['Gercek_Deger'])\n",
        "\n",
        "\n",
        "# 3. VERÄ°YÄ° HAZIRLA\n",
        "# CNN iÃ§in sequence hazÄ±rlÄ±ÄŸÄ± (Bunlar zaten int gelir, sorun Ã§Ä±karmaz)\n",
        "seq_dna = pad_sequences(dna_tok.texts_to_sequences([raw_dna]), maxlen=11, padding='post')\n",
        "seq_prot = pad_sequences(prot_tok.texts_to_sequences([raw_prot]), maxlen=11, padding='post')\n",
        "\n",
        "# *** KRÄ°TÄ°K DÃœZELTME BURADA ***\n",
        "# raw_feats nesne (object) tipinde kalmÄ±ÅŸ olabilir, onu zorla sayÄ±ya (float32) Ã§eviriyoruz.\n",
        "raw_feats = np.asarray(raw_feats).astype('float32')\n",
        "\n",
        "# XGB/LGBM iÃ§in features (Pandas DataFrame olarak vermek uyarÄ±larÄ± engeller)\n",
        "feat_df = pd.DataFrame(raw_feats, columns=['Risk', 'MAF', 'Cons', 'Hydro', 'Polar', 'Weight'])\n",
        "\n",
        "# 4. UZMANLARA DANIÅ (BASE MODELS PREDICTION)\n",
        "print(\"\\n>> ğŸ§  Uzman Modeller DÃ¼ÅŸÃ¼nÃ¼yor...\")\n",
        "\n",
        "# Uzman 1: CNN (OlasÄ±lÄ±k veriyor)\n",
        "# ArtÄ±k raw_feats float32 olduÄŸu iÃ§in hata vermeyecek\n",
        "prob_cnn = model_cnn.predict([seq_dna, seq_prot, raw_feats], verbose=0)[0][0]\n",
        "\n",
        "# Uzman 2: XGBoost (OlasÄ±lÄ±k veriyor - sÄ±nÄ±f 1 iÃ§in)\n",
        "prob_xgb = model_xgb.predict_proba(feat_df)[0][1]\n",
        "\n",
        "# Uzman 3: LightGBM (OlasÄ±lÄ±k veriyor - sÄ±nÄ±f 1 iÃ§in)\n",
        "prob_lgbm = model_lgbm.predict_proba(feat_df)[0][1]\n",
        "\n",
        "print(f\"   - CNN GÃ¶rÃ¼ÅŸÃ¼     : %{prob_cnn*100:.2f} Hasta Olabilir\")\n",
        "print(f\"   - XGBoost GÃ¶rÃ¼ÅŸÃ¼ : %{prob_xgb*100:.2f} Hasta Olabilir\")\n",
        "print(f\"   - LightGBM GÃ¶rÃ¼ÅŸÃ¼: %{prob_lgbm*100:.2f} Hasta Olabilir\")\n",
        "\n",
        "#\n",
        "# 4. UZMANLARA DANIÅ (BASE MODELS PREDICTION)\n",
        "print(\"\\n>> ğŸ§  Uzman Modeller DÃ¼ÅŸÃ¼nÃ¼yor...\")\n",
        "\n",
        "\n",
        "\n",
        "# 5. PATRONA DANIÅ (META LEARNER PREDICTION)\n",
        "# Uzman gÃ¶rÃ¼ÅŸlerini bir vektÃ¶rde topla: [CNN, XGB, LGBM]\n",
        "stack_vector = np.array([[prob_cnn, prob_xgb, prob_lgbm]])\n",
        "\n",
        "# Patron karar versin\n",
        "final_prob = meta_model.predict_proba(stack_vector)[0][1]\n",
        "final_karar = 1 if final_prob > 0.5 else 0\n",
        "\n",
        "# 6. RAPOR\n",
        "print(\"\\n\" + \"=\"*40)\n",
        "print(\"ğŸ¥ STACKING TANI SÄ°STEMÄ° SONUCU\")\n",
        "print(\"=\"*40)\n",
        "print(f\"DNA Dizisi       : {raw_dna}\")\n",
        "print(f\"Biyo-Ä°ÅŸaretler   : Risk={raw_feats[0][0]:.2f}, AÄŸÄ±rlÄ±k={raw_feats[0][5]:.1f}\")\n",
        "print(\"-\" * 40)\n",
        "print(f\"GERÃ‡EK DURUM     : {'HASTA âš ï¸' if gercek_durum==1 else 'SAÄLIKLI âœ…'}\")\n",
        "print(f\"SÄ°STEM TAHMÄ°NÄ°   : {'HASTA âš ï¸' if final_karar==1 else 'SAÄLIKLI âœ…'}\")\n",
        "print(f\"GÃ¼ven Skoru      : %{final_prob*100:.2f}\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "if final_karar == gercek_durum:\n",
        "    print(\"SONUÃ‡: ğŸ† TEBRÄ°KLER! Sistem doÄŸru bildi.\")\n",
        "else:\n",
        "    print(\"SONUÃ‡: âŒ HATA. Sistem yanÄ±ldÄ±.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XLUhhZ05MnE",
        "outputId": "fc8b1eda-42f1-49cc-e030-af14599a0e48"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Modeller ve SÃ¶zlÃ¼kler yÃ¼kleniyor...\n",
            "âœ… Sistem HazÄ±r.\n",
            "\n",
            ">> ğŸ§  Uzman Modeller DÃ¼ÅŸÃ¼nÃ¼yor...\n",
            "   - CNN GÃ¶rÃ¼ÅŸÃ¼     : %0.03 Hasta Olabilir\n",
            "   - XGBoost GÃ¶rÃ¼ÅŸÃ¼ : %0.19 Hasta Olabilir\n",
            "   - LightGBM GÃ¶rÃ¼ÅŸÃ¼: %0.30 Hasta Olabilir\n",
            "\n",
            ">> ğŸ§  Uzman Modeller DÃ¼ÅŸÃ¼nÃ¼yor...\n",
            "\n",
            "========================================\n",
            "ğŸ¥ STACKING TANI SÄ°STEMÄ° SONUCU\n",
            "========================================\n",
            "DNA Dizisi       : TAGCACGGTAG\n",
            "Biyo-Ä°ÅŸaretler   : Risk=0.12, AÄŸÄ±rlÄ±k=17.4\n",
            "----------------------------------------\n",
            "GERÃ‡EK DURUM     : SAÄLIKLI âœ…\n",
            "SÄ°STEM TAHMÄ°NÄ°   : SAÄLIKLI âœ…\n",
            "GÃ¼ven Skoru      : %1.94\n",
            "----------------------------------------\n",
            "SONUÃ‡: ğŸ† TEBRÄ°KLER! Sistem doÄŸru bildi.\n"
          ]
        }
      ]
    }
  ]
}