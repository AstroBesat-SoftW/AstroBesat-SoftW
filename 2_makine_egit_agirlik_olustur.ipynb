{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOE0UBKcCR7HmqZ1pEp6+p9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBesat-SoftW/AstroBesat-SoftW/blob/main/2_makine_egit_agirlik_olustur.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOSYA ADI: egitim.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle # Kayıt işlemleri için\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report, recall_score, cohen_kappa_score\n",
        "\n",
        "# --- 1. ADIM: TEKNOFEST ÜNİVERSİTE VERİSİ OLUŞTURMA ---\n",
        "print(\">> Veri üretiliyor (20.000 Adet)...\")\n",
        "\n",
        "def veri_uret(n):\n",
        "    dna_seqs, prot_seqs, bio_feats, labels = [], [], [], []\n",
        "    amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Genomik (DNA) ve Proteomik (Amino Asit) Komşuluk (11 birim)\n",
        "        dna = ''.join(np.random.choice(list('ACGT'), size=11))\n",
        "        prot = ''.join(np.random.choice(amino_acids, size=11))\n",
        "\n",
        "        # Sayısal Özellikler (Risk, MAF, Korunmuşluk, Hidro, Polarite, Ağırlık)\n",
        "        risk = np.random.beta(2, 2)\n",
        "        maf = np.random.exponential(0.05)\n",
        "        cons = np.random.uniform(0, 10)\n",
        "        hydro = np.random.uniform(-5, 5)\n",
        "        polar = np.random.uniform(-3, 3)\n",
        "        weight = np.random.uniform(-50, 50)\n",
        "\n",
        "        # Etiketleme Kuralı (Simülasyon)\n",
        "        score = (risk * 0.4) + (cons/10 * 0.2) + ((0.5 - maf)*2 * 0.2) + (abs(hydro)/5 * 0.2)\n",
        "        score += np.random.normal(0, 0.05)\n",
        "        label = 1 if score > 0.65 else 0\n",
        "\n",
        "        dna_seqs.append(dna)\n",
        "        prot_seqs.append(prot)\n",
        "        bio_feats.append([risk, maf, cons, hydro, polar, weight])\n",
        "        labels.append(label)\n",
        "\n",
        "    return dna_seqs, prot_seqs, np.array(bio_feats), np.array(labels)\n",
        "\n",
        "dna_data, prot_data, num_data, y = veri_uret(20000)\n",
        "\n",
        "# --- 2. ADIM: VERİYİ İŞLEME VE HAZIRLAMA ---\n",
        "# DNA Tokenizer\n",
        "dna_tok = Tokenizer(char_level=True)\n",
        "dna_tok.fit_on_texts(dna_data)\n",
        "X_dna = pad_sequences(dna_tok.texts_to_sequences(dna_data), maxlen=11, padding='post')\n",
        "\n",
        "# Protein Tokenizer\n",
        "prot_tok = Tokenizer(char_level=True)\n",
        "prot_tok.fit_on_texts(prot_data)\n",
        "X_prot = pad_sequences(prot_tok.texts_to_sequences(prot_data), maxlen=11, padding='post')\n",
        "\n",
        "# Eğitim/Test Ayrımı\n",
        "X_dna_tr, X_dna_ts, X_prot_tr, X_prot_ts, X_num_tr, X_num_ts, y_tr, y_ts = train_test_split(\n",
        "    X_dna, X_prot, num_data, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- 3. ADIM: MODEL MİMARİSİ (3 GİRDİLİ) ---\n",
        "# Giriş 1: DNA\n",
        "in_dna = Input(shape=(11,))\n",
        "emb_dna = Embedding(len(dna_tok.word_index)+1, 8)(in_dna)\n",
        "x1 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_dna))\n",
        "\n",
        "# Giriş 2: Protein\n",
        "in_prot = Input(shape=(11,))\n",
        "emb_prot = Embedding(len(prot_tok.word_index)+1, 8)(in_prot)\n",
        "x2 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_prot))\n",
        "\n",
        "# Giriş 3: Sayısal Veriler\n",
        "in_num = Input(shape=(6,))\n",
        "x3 = BatchNormalization()(Dense(16, activation='relu')(in_num))\n",
        "\n",
        "# Birleştirme\n",
        "merged = Concatenate()([x1, x2, x3])\n",
        "z = Dropout(0.4)(Dense(64, activation='relu')(merged))\n",
        "out = Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "model = Model(inputs=[in_dna, in_prot, in_num], outputs=out)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- 4. ADIM: EĞİTİM ---\n",
        "print(\">> Model Eğitiliyor...\")\n",
        "model.fit([X_dna_tr, X_prot_tr, X_num_tr], y_tr, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
        "\n",
        "# --- 5. ADIM: RAPORLAMA ---\n",
        "print(\"\\n>> Performans Hesaplanıyor...\")\n",
        "preds = (model.predict([X_dna_ts, X_prot_ts, X_num_ts]) > 0.5).astype(int)\n",
        "\n",
        "print(f\"F1 Skoru : {f1_score(y_ts, preds):.4f}\")\n",
        "print(f\"Kappa    : {cohen_kappa_score(y_ts, preds):.4f}\")\n",
        "print(f\"Recall   : {recall_score(y_ts, preds):.4f}\")\n",
        "\n",
        "# --- 6. ADIM: KAYDETME (EN ÖNEMLİ KISIM) ---\n",
        "print(\"\\n>> Dosyalar kaydediliyor (Bir sonraki kod için)...\")\n",
        "\n",
        "# Modeli kaydet (.h5)\n",
        "model.save('teknofest_beyni.h5')\n",
        "\n",
        "# Tokenizer'ları kaydet (Harf çeviriciler)\n",
        "with open('dna_sozlugu.pickle', 'wb') as f:\n",
        "    pickle.dump(dna_tok, f)\n",
        "\n",
        "with open('prot_sozlugu.pickle', 'wb') as f:\n",
        "    pickle.dump(prot_tok, f)\n",
        "\n",
        "print(\"✅ BİTTİ! 'teknofest_beyni.h5', 'dna_sozlugu.pickle' ve 'prot_sozlugu.pickle' oluştu.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTeJdlWYzOHe",
        "outputId": "ed0a9aad-71bd-4023-f124-a547aac4f42b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Veri üretiliyor (20.000 Adet)...\n",
            ">> Model Eğitiliyor...\n",
            "Epoch 1/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.6718 - loss: 0.6093 - val_accuracy: 0.7275 - val_loss: 0.5386\n",
            "Epoch 2/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7613 - loss: 0.4882 - val_accuracy: 0.7181 - val_loss: 0.5601\n",
            "Epoch 3/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8654 - loss: 0.3056 - val_accuracy: 0.8863 - val_loss: 0.2647\n",
            "Epoch 4/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8798 - loss: 0.2723 - val_accuracy: 0.8550 - val_loss: 0.3079\n",
            "Epoch 5/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8808 - loss: 0.2683 - val_accuracy: 0.8944 - val_loss: 0.2428\n",
            "Epoch 6/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8865 - loss: 0.2561 - val_accuracy: 0.8894 - val_loss: 0.2394\n",
            "Epoch 7/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8796 - loss: 0.2640 - val_accuracy: 0.8950 - val_loss: 0.2363\n",
            "Epoch 8/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8862 - loss: 0.2569 - val_accuracy: 0.8988 - val_loss: 0.2415\n",
            "Epoch 9/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.2544 - val_accuracy: 0.8944 - val_loss: 0.2389\n",
            "Epoch 10/10\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8905 - loss: 0.2520 - val_accuracy: 0.8938 - val_loss: 0.2337\n",
            "\n",
            ">> Performans Hesaplanıyor...\n",
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Skoru : 0.8220\n",
            "Kappa    : 0.7476\n",
            "Recall   : 0.8193\n",
            "\n",
            ">> Dosyalar kaydediliyor (Bir sonraki kod için)...\n",
            "✅ BİTTİ! 'teknofest_beyni.h5', 'dna_sozlugu.pickle' ve 'prot_sozlugu.pickle' oluştu.\n"
          ]
        }
      ]
    }
  ]
}