{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAlB3lmreT43mGEGvcTciQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBesat-SoftW/AstroBesat-SoftW/blob/main/makine_e%C4%9Fitim_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report, recall_score, cohen_kappa_score, precision_score, accuracy_score\n",
        "\n",
        "# --- 1. ADIM: VERÄ° ÃœRETÄ°MÄ° (TEKNOFEST Ãœniversite Åartnamesi) ---\n",
        "n_samples = 200000\n",
        "print(f\"TEKNOFEST 2026 Ãœniversite Åartnamesine uygun {n_samples} veri Ã¼retiliyor...\")\n",
        "\n",
        "def generate_university_level_data(n):\n",
        "    dna_seqs = []\n",
        "    protein_seqs = []\n",
        "    bio_features = []\n",
        "    labels = []\n",
        "    amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Genomik ve Proteomik KomÅŸuluk (11 birim)\n",
        "        dna_fragment = ''.join(np.random.choice(list('ACGT'), size=11))\n",
        "        prot_fragment = ''.join(np.random.choice(amino_acids, size=11))\n",
        "\n",
        "        # Biyolojik Ã–zellikler\n",
        "        risk_score = np.random.beta(2, 2)\n",
        "        maf = np.random.exponential(0.05)\n",
        "        if maf > 0.5: maf = 0.5\n",
        "        conservation = np.random.uniform(0, 10)\n",
        "        hydrophobicity_change = np.random.uniform(-5, 5)\n",
        "        polarity_change = np.random.uniform(-3, 3)\n",
        "        mol_weight_change = np.random.uniform(-50, 50)\n",
        "\n",
        "        # Etiketleme MantÄ±ÄŸÄ±\n",
        "        pathogenicity_index = (risk_score * 0.4) + (conservation/10 * 0.2) + ((0.5 - maf)*2 * 0.2) + (abs(hydrophobicity_change)/5 * 0.2)\n",
        "        pathogenicity_index += np.random.normal(0, 0.05)\n",
        "\n",
        "        if pathogenicity_index > 0.65:\n",
        "            labels.append(1) # Patojenik\n",
        "        else:\n",
        "            labels.append(0) # Benign\n",
        "\n",
        "        dna_seqs.append(dna_fragment)\n",
        "        protein_seqs.append(prot_fragment)\n",
        "        bio_features.append([risk_score, maf, conservation, hydrophobicity_change, polarity_change, mol_weight_change])\n",
        "\n",
        "    return dna_seqs, protein_seqs, np.array(bio_features), np.array(labels)\n",
        "\n",
        "dna_sequences, protein_sequences, X_numerical, y = generate_university_level_data(n_samples)\n",
        "\n",
        "# --- 2. ADIM: VERÄ° KAYDI ---\n",
        "print(\">> Veriler 'teknofest_univ_egitim_seti.txt' dosyasÄ±na kaydediliyor...\")\n",
        "df_data = pd.DataFrame(X_numerical, columns=['Risk_Skoru', 'MAF', 'Korunmusluk', 'Hidrofobiklik', 'Polarite', 'Mol_Agirlik'])\n",
        "df_data.insert(0, 'Genomik_Komsuluk', dna_sequences)\n",
        "df_data.insert(1, 'Proteomik_Komsuluk', protein_sequences)\n",
        "df_data['SINIF_ETIKETI'] = y\n",
        "df_data.to_csv('teknofest_univ_egitim_seti.txt', sep='\\t', index=False)\n",
        "print(\">> KayÄ±t BaÅŸarÄ±lÄ±!\\n\")\n",
        "\n",
        "# --- 3. ADIM: Ã–N Ä°ÅLEME ---\n",
        "dna_tokenizer = Tokenizer(char_level=True)\n",
        "dna_tokenizer.fit_on_texts(dna_sequences)\n",
        "X_dna = pad_sequences(dna_tokenizer.texts_to_sequences(dna_sequences), maxlen=11, padding='post')\n",
        "\n",
        "prot_tokenizer = Tokenizer(char_level=True)\n",
        "prot_tokenizer.fit_on_texts(protein_sequences)\n",
        "X_prot = pad_sequences(prot_tokenizer.texts_to_sequences(protein_sequences), maxlen=11, padding='post')\n",
        "\n",
        "X_num = X_numerical\n",
        "\n",
        "X_dna_train, X_dna_test, X_prot_train, X_prot_test, X_num_train, X_num_test, y_train, y_test = train_test_split(\n",
        "    X_dna, X_prot, X_num, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- 4. ADIM: MODEL MÄ°MARÄ°SÄ° ---\n",
        "input_dna = Input(shape=(11,), name=\"DNA_Input\")\n",
        "emb_dna = Embedding(len(dna_tokenizer.word_index)+1, 8, input_length=11)(input_dna)\n",
        "pool_dna = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_dna))\n",
        "\n",
        "input_prot = Input(shape=(11,), name=\"Protein_Input\")\n",
        "emb_prot = Embedding(len(prot_tokenizer.word_index)+1, 8, input_length=11)(input_prot)\n",
        "pool_prot = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_prot))\n",
        "\n",
        "input_num = Input(shape=(6,), name=\"Bio_Features_Input\")\n",
        "norm_num = BatchNormalization()(Dense(16, activation='relu')(input_num))\n",
        "\n",
        "merged = Concatenate()([pool_dna, pool_prot, norm_num])\n",
        "z = Dropout(0.4)(Dense(64, activation='relu')(merged))\n",
        "z = Dense(32, activation='relu')(z)\n",
        "output = Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "model = Model(inputs=[input_dna, input_prot, input_num], outputs=output)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- 5. ADIM: EÄÄ°TÄ°M ---\n",
        "print(\"Model EÄŸitiliyor...\")\n",
        "model.fit([X_dna_train, X_prot_train, X_num_train], y_train, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
        "\n",
        "# --- 6. ADIM: DETAYLI PERFORMANS ANALÄ°ZÄ° ---\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"   TEKNOFEST MODEL PERFORMANS RAPORU\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "y_pred_prob = model.predict([X_dna_test, X_prot_test, X_num_test])\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)\n",
        "\n",
        "# Metriklerin HesaplanmasÄ±\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(f\"âœ… Accuracy (DoÄŸruluk)     : {acc:.4f}\")\n",
        "print(f\"ğŸ¯ Recall (DuyarlÄ±lÄ±k)     : {rec:.4f}  <-- HastalarÄ± yakalama oranÄ±\")\n",
        "print(f\"ğŸ‘Œ Precision (Kesinlik)    : {prec:.4f}\")\n",
        "print(f\"ğŸ† F1 Score (Denge Skoru)  : {f1:.4f}  <-- Åartname Kriteri\")\n",
        "print(f\"âš–ï¸  Cohen's Kappa           : {kappa:.4f}  <-- Åans faktÃ¶rÃ¼nden arÄ±ndÄ±rÄ±lmÄ±ÅŸ baÅŸarÄ±\")\n",
        "\n",
        "print(\"-\" * 50)\n",
        "print(\"DETAYLI SINIFLANDIRMA RAPORU:\")\n",
        "print(classification_report(y_test, y_pred, target_names=['Benign (SaÄŸlÄ±klÄ±)', 'Patojenik (Hasta)']))\n",
        "print(\"=\"*50)\n",
        "\n",
        "# --- 7. ADIM: SONUÃ‡LARI KAYDETME ---\n",
        "test_dna_texts = [t.replace(' ', '').upper() for t in dna_tokenizer.sequences_to_texts(X_dna_test)]\n",
        "test_prot_texts = [t.replace(' ', '').upper() for t in prot_tokenizer.sequences_to_texts(X_prot_test)]\n",
        "\n",
        "df_result = pd.DataFrame(X_num_test, columns=['Risk_Skoru', 'MAF', 'Korunmusluk', 'Hidrofobiklik', 'Polarite', 'Mol_Agirlik'])\n",
        "df_result.insert(0, 'DNA_Dizisi', test_dna_texts)\n",
        "df_result.insert(1, 'Protein_Dizisi', test_prot_texts)\n",
        "df_result['Gercek_Deger'] = y_test\n",
        "df_result['Tahmin_Degeri'] = y_pred.flatten()\n",
        "df_result['Olasilik'] = y_pred_prob.flatten()\n",
        "df_result['SONUC'] = np.where(df_result['Gercek_Deger'] == df_result['Tahmin_Degeri'], 'DOGRU', 'YANLIS')\n",
        "\n",
        "df_result.to_csv('teknofest_univ_test_sonuclari.txt', sep='\\t', index=False)\n",
        "print(\">> DetaylÄ± sonuÃ§lar 'teknofest_univ_test_sonuclari.txt' dosyasÄ±na kaydedildi.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTeJdlWYzOHe",
        "outputId": "e13f687c-fb4b-4129-e141-afab6241f816"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TEKNOFEST 2026 Ãœniversite Åartnamesine uygun 200000 veri Ã¼retiliyor...\n",
            ">> Veriler 'teknofest_univ_egitim_seti.txt' dosyasÄ±na kaydediliyor...\n",
            ">> KayÄ±t BaÅŸarÄ±lÄ±!\n",
            "\n",
            "Model EÄŸitiliyor...\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7764 - loss: 0.4536 - val_accuracy: 0.8914 - val_loss: 0.2410\n",
            "Epoch 2/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8829 - loss: 0.2638 - val_accuracy: 0.8873 - val_loss: 0.2461\n",
            "Epoch 3/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8843 - loss: 0.2583 - val_accuracy: 0.8905 - val_loss: 0.2397\n",
            "Epoch 4/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.2537 - val_accuracy: 0.8871 - val_loss: 0.2429\n",
            "Epoch 5/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8845 - loss: 0.2577 - val_accuracy: 0.8898 - val_loss: 0.2422\n",
            "Epoch 6/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8838 - loss: 0.2562 - val_accuracy: 0.8882 - val_loss: 0.2432\n",
            "Epoch 7/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8850 - loss: 0.2554 - val_accuracy: 0.8904 - val_loss: 0.2414\n",
            "Epoch 8/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2537 - val_accuracy: 0.8896 - val_loss: 0.2454\n",
            "Epoch 9/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8851 - loss: 0.2546 - val_accuracy: 0.8913 - val_loss: 0.2388\n",
            "Epoch 10/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8874 - loss: 0.2531 - val_accuracy: 0.8871 - val_loss: 0.2429\n",
            "\n",
            "==================================================\n",
            "   TEKNOFEST MODEL PERFORMANS RAPORU\n",
            "==================================================\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "âœ… Accuracy (DoÄŸruluk)     : 0.8934\n",
            "ğŸ¯ Recall (DuyarlÄ±lÄ±k)     : 0.8102  <-- HastalarÄ± yakalama oranÄ±\n",
            "ğŸ‘Œ Precision (Kesinlik)    : 0.8350\n",
            "ğŸ† F1 Score (Denge Skoru)  : 0.8224  <-- Åartname Kriteri\n",
            "âš–ï¸  Cohen's Kappa           : 0.7463  <-- Åans faktÃ¶rÃ¼nden arÄ±ndÄ±rÄ±lmÄ±ÅŸ baÅŸarÄ±\n",
            "--------------------------------------------------\n",
            "DETAYLI SINIFLANDIRMA RAPORU:\n",
            "                   precision    recall  f1-score   support\n",
            "\n",
            "Benign (SaÄŸlÄ±klÄ±)       0.92      0.93      0.92     27812\n",
            "Patojenik (Hasta)       0.84      0.81      0.82     12188\n",
            "\n",
            "         accuracy                           0.89     40000\n",
            "        macro avg       0.88      0.87      0.87     40000\n",
            "     weighted avg       0.89      0.89      0.89     40000\n",
            "\n",
            "==================================================\n",
            ">> DetaylÄ± sonuÃ§lar 'teknofest_univ_test_sonuclari.txt' dosyasÄ±na kaydedildi.\n"
          ]
        }
      ]
    }
  ]
}