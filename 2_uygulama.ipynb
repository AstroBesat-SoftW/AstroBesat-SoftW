{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4mmG6YGccIvbX08WQP2qa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AstroBesat-SoftW/AstroBesat-SoftW/blob/main/2_uygulama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DOSYA ADI: egitim.py\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import pickle # KayÄ±t iÅŸlemleri iÃ§in\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Concatenate, Dropout, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, classification_report, recall_score, cohen_kappa_score\n",
        "\n",
        "# --- 1. ADIM: TEKNOFEST ÃœNÄ°VERSÄ°TE VERÄ°SÄ° OLUÅTURMA ---\n",
        "print(\">> Veri Ã¼retiliyor (200.000 Adet)...\")\n",
        "\n",
        "def veri_uret(n):\n",
        "    dna_seqs, prot_seqs, bio_feats, labels = [], [], [], []\n",
        "    amino_acids = list(\"ACDEFGHIKLMNPQRSTVWY\")\n",
        "\n",
        "    for _ in range(n):\n",
        "        # Genomik (DNA) ve Proteomik (Amino Asit) KomÅŸuluk (11 birim)\n",
        "        dna = ''.join(np.random.choice(list('ACGT'), size=11))\n",
        "        prot = ''.join(np.random.choice(amino_acids, size=11))\n",
        "\n",
        "        # SayÄ±sal Ã–zellikler (Risk, MAF, KorunmuÅŸluk, Hidro, Polarite, AÄŸÄ±rlÄ±k)\n",
        "        risk = np.random.beta(2, 2)\n",
        "        maf = np.random.exponential(0.05)\n",
        "        cons = np.random.uniform(0, 10)\n",
        "        hydro = np.random.uniform(-5, 5)\n",
        "        polar = np.random.uniform(-3, 3)\n",
        "        weight = np.random.uniform(-50, 50)\n",
        "\n",
        "        # Etiketleme KuralÄ± (SimÃ¼lasyon)\n",
        "        score = (risk * 0.4) + (cons/10 * 0.2) + ((0.5 - maf)*2 * 0.2) + (abs(hydro)/5 * 0.2)\n",
        "        score += np.random.normal(0, 0.05)\n",
        "        label = 1 if score > 0.65 else 0\n",
        "\n",
        "        dna_seqs.append(dna)\n",
        "        prot_seqs.append(prot)\n",
        "        bio_feats.append([risk, maf, cons, hydro, polar, weight])\n",
        "        labels.append(label)\n",
        "\n",
        "    return dna_seqs, prot_seqs, np.array(bio_feats), np.array(labels)\n",
        "\n",
        "dna_data, prot_data, num_data, y = veri_uret(200000)\n",
        "\n",
        "# --- 2. ADIM: VERÄ°YÄ° Ä°ÅLEME VE HAZIRLAMA ---\n",
        "# DNA Tokenizer\n",
        "dna_tok = Tokenizer(char_level=True)\n",
        "dna_tok.fit_on_texts(dna_data)\n",
        "X_dna = pad_sequences(dna_tok.texts_to_sequences(dna_data), maxlen=11, padding='post')\n",
        "\n",
        "# Protein Tokenizer\n",
        "prot_tok = Tokenizer(char_level=True)\n",
        "prot_tok.fit_on_texts(prot_data)\n",
        "X_prot = pad_sequences(prot_tok.texts_to_sequences(prot_data), maxlen=11, padding='post')\n",
        "\n",
        "# EÄŸitim/Test AyrÄ±mÄ±\n",
        "X_dna_tr, X_dna_ts, X_prot_tr, X_prot_ts, X_num_tr, X_num_ts, y_tr, y_ts = train_test_split(\n",
        "    X_dna, X_prot, num_data, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# --- 3. ADIM: MODEL MÄ°MARÄ°SÄ° (3 GÄ°RDÄ°LÄ°) ---\n",
        "# GiriÅŸ 1: DNA\n",
        "in_dna = Input(shape=(11,))\n",
        "emb_dna = Embedding(len(dna_tok.word_index)+1, 8)(in_dna)\n",
        "x1 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_dna))\n",
        "\n",
        "# GiriÅŸ 2: Protein\n",
        "in_prot = Input(shape=(11,))\n",
        "emb_prot = Embedding(len(prot_tok.word_index)+1, 8)(in_prot)\n",
        "x2 = GlobalMaxPooling1D()(Conv1D(16, 3, activation='relu')(emb_prot))\n",
        "\n",
        "# GiriÅŸ 3: SayÄ±sal Veriler\n",
        "in_num = Input(shape=(6,))\n",
        "x3 = BatchNormalization()(Dense(16, activation='relu')(in_num))\n",
        "\n",
        "# BirleÅŸtirme\n",
        "merged = Concatenate()([x1, x2, x3])\n",
        "z = Dropout(0.4)(Dense(64, activation='relu')(merged))\n",
        "out = Dense(1, activation='sigmoid')(z)\n",
        "\n",
        "model = Model(inputs=[in_dna, in_prot, in_num], outputs=out)\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# --- 4. ADIM: EÄÄ°TÄ°M ---\n",
        "print(\">> Model EÄŸitiliyor...\")\n",
        "model.fit([X_dna_tr, X_prot_tr, X_num_tr], y_tr, epochs=10, batch_size=64, validation_split=0.1, verbose=1)\n",
        "\n",
        "# --- 5. ADIM: RAPORLAMA ---\n",
        "print(\"\\n>> Performans HesaplanÄ±yor...\")\n",
        "preds = (model.predict([X_dna_ts, X_prot_ts, X_num_ts]) > 0.5).astype(int)\n",
        "\n",
        "print(f\"F1 Skoru : {f1_score(y_ts, preds):.4f}\")\n",
        "print(f\"Kappa    : {cohen_kappa_score(y_ts, preds):.4f}\")\n",
        "print(f\"Recall   : {recall_score(y_ts, preds):.4f}\")\n",
        "\n",
        "# --- 6. ADIM: KAYDETME (EN Ã–NEMLÄ° KISIM) ---\n",
        "print(\"\\n>> Dosyalar kaydediliyor (Bir sonraki kod iÃ§in)...\")\n",
        "\n",
        "# Modeli kaydet (.h5)\n",
        "model.save('model/teknofest_beyni.h5')\n",
        "\n",
        "# Tokenizer'larÄ± kaydet (Harf Ã§eviriciler)\n",
        "with open('model/dna_sozlugu.pickle', 'wb') as f:\n",
        "    pickle.dump(dna_tok, f)\n",
        "\n",
        "with open('model/prot_sozlugu.pickle', 'wb') as f:\n",
        "    pickle.dump(prot_tok, f)\n",
        "\n",
        "print(\"âœ… BÄ°TTÄ°! 'teknofest_beyni.h5', 'dna_sozlugu.pickle' ve 'prot_sozlugu.pickle' oluÅŸtu.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTeJdlWYzOHe",
        "outputId": "d6fb0e5a-9cbe-4a0c-feab-18e42f6bfa61"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Veri Ã¼retiliyor (200.000 Adet)...\n",
            ">> Model EÄŸitiliyor...\n",
            "Epoch 1/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 4ms/step - accuracy: 0.7934 - loss: 0.4258 - val_accuracy: 0.8948 - val_loss: 0.2369\n",
            "Epoch 2/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8844 - loss: 0.2609 - val_accuracy: 0.8869 - val_loss: 0.2551\n",
            "Epoch 3/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8859 - loss: 0.2567 - val_accuracy: 0.8933 - val_loss: 0.2349\n",
            "Epoch 4/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.2538 - val_accuracy: 0.9004 - val_loss: 0.2287\n",
            "Epoch 5/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8866 - loss: 0.2554 - val_accuracy: 0.8976 - val_loss: 0.2343\n",
            "Epoch 6/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8860 - loss: 0.2551 - val_accuracy: 0.8959 - val_loss: 0.2326\n",
            "Epoch 7/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.2544 - val_accuracy: 0.8984 - val_loss: 0.2300\n",
            "Epoch 8/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.2505 - val_accuracy: 0.8991 - val_loss: 0.2288\n",
            "Epoch 9/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8899 - loss: 0.2499 - val_accuracy: 0.8979 - val_loss: 0.2293\n",
            "Epoch 10/10\n",
            "\u001b[1m2250/2250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.2523 - val_accuracy: 0.9005 - val_loss: 0.2288\n",
            "\n",
            ">> Performans HesaplanÄ±yor...\n",
            "\u001b[1m1250/1250\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F1 Skoru : 0.8288\n",
            "Kappa    : 0.7533\n",
            "Recall   : 0.8247\n",
            "\n",
            ">> Dosyalar kaydediliyor (Bir sonraki kod iÃ§in)...\n",
            "âœ… BÄ°TTÄ°! 'teknofest_beyni.h5', 'dna_sozlugu.pickle' ve 'prot_sozlugu.pickle' oluÅŸtu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# 1. MODELÄ° VE SÃ–ZLÃœKLERÄ° YÃœKLE\n",
        "print(\">> Model ve sÃ¶zlÃ¼kler yÃ¼kleniyor...\")\n",
        "model = load_model('model/teknofest_beyni.h5')\n",
        "\n",
        "with open('model/dna_sozlugu.pickle', 'rb') as f:\n",
        "    dna_tok = pickle.load(f)\n",
        "\n",
        "with open('model/prot_sozlugu.pickle', 'rb') as f:\n",
        "    prot_tok = pickle.load(f)\n",
        "\n",
        "# 2. GERÃ‡EK CEVAPLARIN OLDUÄU DOSYAYI YÃœKLE\n",
        "# Ã–nceki eÄŸitimde kaydettiÄŸimiz dosyayÄ± okuyoruz\n",
        "print(\">> Test sonuÃ§larÄ± dosyasÄ± okunuyor...\")\n",
        "try:\n",
        "    df = pd.read_csv('teknofest_univ_test_sonuclari.txt', sep='\\t')\n",
        "except FileNotFoundError:\n",
        "    print(\"HATA: 'teknofest_univ_test_sonuclari.txt' dosyasÄ± bulunamadÄ±!\")\n",
        "    print(\"LÃ¼tfen Ã¶nce egitim.py kodunu Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±nÄ±zdan emin olun.\")\n",
        "    exit()\n",
        "\n",
        "# 3. RASTGELE BÄ°R HASTA SEÃ‡ (SaÄŸlamasÄ±nÄ± yapmak iÃ§in)\n",
        "rastgele_satir = df.sample(1).iloc[0]\n",
        "\n",
        "# SeÃ§ilen hastanÄ±n verilerini al\n",
        "gercek_dna = rastgele_satir['DNA_Dizisi']\n",
        "gercek_prot = rastgele_satir['Protein_Dizisi']\n",
        "gercek_durum = rastgele_satir['Gercek_Deger'] # 1 (Hasta) veya 0 (SaÄŸlÄ±klÄ±)\n",
        "\n",
        "# SayÄ±sal verileri al: [Risk, MAF, Korunmusluk, Hidro, Polar, Mol_Agirlik]\n",
        "gelen_veri = np.array([[\n",
        "    rastgele_satir['Risk_Skoru'],\n",
        "    rastgele_satir['MAF'],\n",
        "    rastgele_satir['Korunmusluk'],\n",
        "    rastgele_satir['Hidrofobiklik'],\n",
        "    rastgele_satir['Polarite'],\n",
        "    rastgele_satir['Mol_Agirlik']\n",
        "]])\n",
        "\n",
        "# 4. MODEL Ä°Ã‡Ä°N HAZIRLA\n",
        "seq_dna = pad_sequences(dna_tok.texts_to_sequences([gercek_dna]), maxlen=11, padding='post')\n",
        "seq_prot = pad_sequences(prot_tok.texts_to_sequences([gercek_prot]), maxlen=11, padding='post')\n",
        "\n",
        "# 5. MODELE SOR\n",
        "tahmin_olasiligi = model.predict([seq_dna, seq_prot, gelen_veri])[0][0]\n",
        "model_karari = 1 if tahmin_olasiligi > 0.5 else 0\n",
        "\n",
        "# 6. KARÅILAÅTIRMA RAPORU\n",
        "durum_metni = lambda x: \"PATOJENÄ°K (HASTA) âš ï¸\" if x == 1 else \"BENIGN (SAÄLIKLI) âœ…\"\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(f\"ğŸ§ª DOÄRULAMA TESTÄ°\")\n",
        "print(\"=\"*50)\n",
        "print(f\"SeÃ§ilen DNA      : {gercek_dna}\")\n",
        "print(f\"Risk Skoru (Veri): {rastgele_satir['Risk_Skoru']:.4f}\")\n",
        "print(\"-\" * 50)\n",
        "print(f\"GERÃ‡EK DURUM     : {durum_metni(gercek_durum)}\")\n",
        "print(f\"MODEL TAHMÄ°NÄ°    : {durum_metni(model_karari)} (OlasÄ±lÄ±k: %{tahmin_olasiligi*100:.2f})\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "if gercek_durum == model_karari:\n",
        "    print(\"SONUÃ‡: ğŸ† MÃœKEMMEL! Model doÄŸru bildi.\")\n",
        "else:\n",
        "    print(\"SONUÃ‡: âŒ HATA. Model bu zor Ã¶rnekte yanÄ±ldÄ±.\")\n",
        "print(\"=\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XLUhhZ05MnE",
        "outputId": "a1ed0bf4-3505-41d4-bf67-8e78b69a77f0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">> Model ve sÃ¶zlÃ¼kler yÃ¼kleniyor...\n",
            ">> Test sonuÃ§larÄ± dosyasÄ± okunuyor...\n",
            "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step\n",
            "\n",
            "==================================================\n",
            "ğŸ§ª DOÄRULAMA TESTÄ°\n",
            "==================================================\n",
            "SeÃ§ilen DNA      : CCGCTAAATTA\n",
            "Risk Skoru (Veri): 0.6052\n",
            "--------------------------------------------------\n",
            "GERÃ‡EK DURUM     : PATOJENÄ°K (HASTA) âš ï¸\n",
            "MODEL TAHMÄ°NÄ°    : PATOJENÄ°K (HASTA) âš ï¸ (OlasÄ±lÄ±k: %62.92)\n",
            "--------------------------------------------------\n",
            "SONUÃ‡: ğŸ† MÃœKEMMEL! Model doÄŸru bildi.\n",
            "==================================================\n"
          ]
        }
      ]
    }
  ]
}